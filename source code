# plant
import os
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define constants
MODULE_HANDLE = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2'
IMAGE_SIZE = (224, 224)
NUM_CLASSES = 4
train_dir = 'old_disease/dataset/train'  # Update the directory path
test_dir = 'old_disease/dataset/test'    # Update the directory path

# Check if directories exist
if not os.path.exists(train_dir):
    raise FileNotFoundError(f"Train directory '{train_dir}' not found.")
if not os.path.exists(test_dir):
    raise FileNotFoundError(f"Test directory '{test_dir}' not found.")

# Define model creation function
def create_model():
    feature_extractor = hub.KerasLayer(
        MODULE_HANDLE,
        input_shape=IMAGE_SIZE + (3,),  # Input shape of images (height, width, channels)
        trainable=False  # Freeze the weights of the pre-trained model
    )
    
    model = models.Sequential([
        feature_extractor,
        layers.Dense(NUM_CLASSES, activation='softmax')  # Output layer with softmax activation for classification
    ])
    
    return model

# Create an instance of the model
model = create_model()

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Set up data generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

validation_datagen = ImageDataGenerator(rescale=1./255)

# Flow training images in batches of 32 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical'
)

# Flow validation images in batches of 32 using validation_datagen generator
validation_generator = validation_datagen.flow_from_directory(
    test_dir,
    target_size=IMAGE_SIZE,
    batch_size=32,
    class_mode='categorical'
)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples/train_generator.batch_size,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples/validation_generator.batch_size
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(validation_generator)
print('Test Accuracy:', test_accuracy)

# Save the model
model.save("newmodel.h5")
